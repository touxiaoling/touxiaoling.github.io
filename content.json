{"meta":{"title":"tomin的个人博客","subtitle":"从输入到输出","description":"不要再拖延啦!","author":"tomin","url":"https://blog.ftomin.com","root":"/"},"pages":[{"title":"about","date":"2025-10-11T11:59:56.597Z","updated":"2025-10-11T11:59:56.597Z","comments":true,"path":"about/index.html","permalink":"https://blog.ftomin.com/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2025-10-11T11:59:56.597Z","updated":"2025-10-11T11:59:56.597Z","comments":true,"path":"categories/index.html","permalink":"https://blog.ftomin.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2025-10-11T11:59:56.599Z","updated":"2025-10-11T11:59:56.599Z","comments":true,"path":"tags/index.html","permalink":"https://blog.ftomin.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"pHash 算法探究","slug":"pash算法探究","date":"2025-06-30T10:18:04.000Z","updated":"2025-06-30T10:23:11.000Z","comments":true,"path":"posts/51c06f9f.html","permalink":"https://blog.ftomin.com/posts/51c06f9f.html","excerpt":"1. 算法简介与原理pHash（感知哈希算法，Perceptual Hash Algorithm）是一种基于图像感知特征的哈希算法。它能够将图像转换为固定长度的哈希值，即使图像经过有损压缩、缩放、亮度调整等变换，生成的哈希值仍然保持相似性，从而实现对相似图像的快速识别与匹配。 该算法的原始思路可参考 Looks-Like-It。","text":"1. 算法简介与原理pHash（感知哈希算法，Perceptual Hash Algorithm）是一种基于图像感知特征的哈希算法。它能够将图像转换为固定长度的哈希值，即使图像经过有损压缩、缩放、亮度调整等变换，生成的哈希值仍然保持相似性，从而实现对相似图像的快速识别与匹配。 该算法的原始思路可参考 Looks-Like-It。 pHash 算法的基本流程如下： 将图像转换为灰度图，并缩放到固定尺寸（通常为 32×32 像素）； 应用二维离散余弦变换（DCT），提取低频特征（通常为左上角的 8×8 区域）； 计算 DCT 系数的平均值或中位数； 将 DCT 系数与该值比较，生成二进制哈希值。 但在实际实现中，存在一些细节差异，导致不同实现生成的哈希值可能不同，区分度也会有所影响。主要差异包括： 图像缩放的处理方式； 采用平均值还是中位数作为阈值； 8×8 DCT 系数的排列顺序； 比较时是”大于”还是”大于等于”。 2. 主流实现分析（C++ pHash）我查阅了一些参考实现，例如 pHash 官方网站，其代码位于 aetilius&#x2F;pHash（截至目前有 595 个 star，许多语言的 pHash 实现都直接调用该库）。我们可以分析其 src/pHash.cpp 部分的核心代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243static const CImg&lt;float&gt; dct_matrix = ph_dct_matrix(32);int ph_dct_imagehash(const char *file, ulong64 &amp;hash) &#123; if (!file) &#123; return -1; &#125; CImg&lt;uint8_t&gt; src; try &#123; src.load(file); &#125; catch (CImgIOException &amp;ex) &#123; return -1; &#125; CImg&lt;float&gt; meanfilter(7, 7, 1, 1, 1); CImg&lt;float&gt; img; if (src.spectrum() == 3) &#123; img = src.RGBtoYCbCr().channel(0).get_convolve(meanfilter); &#125; else if (src.spectrum() == 4) &#123; int width = src.width(); int height = src.height(); img = src.crop(0, 0, 0, 0, width - 1, height - 1, 0, 2) .RGBtoYCbCr() .channel(0) .get_convolve(meanfilter); &#125; else &#123; img = src.channel(0).get_convolve(meanfilter); &#125; img.resize(32, 32); const CImg&lt;float&gt; &amp;C = dct_matrix; CImg&lt;float&gt; Ctransp = C.get_transpose(); CImg&lt;float&gt; dctImage = (C)*img * Ctransp; CImg&lt;float&gt; subsec = dctImage.crop(1, 1, 8, 8).unroll(&#x27;x&#x27;); float median = subsec.median(); hash = 0; for (int i = 0; i &lt; 64; i++, hash &lt;&lt;= 1) &#123; float current = subsec(i); if (current &gt; median) hash |= 0x01; &#125; return 0;&#125; 步骤说明： 加载图片后，先将其转换为灰度图像。对于 RGB 图像，先转为 YCbCr 格式，再取亮度通道（channel 0）； 对图像进行均值滤波（mean filter），这一步在很多博客中未提及； 将图像缩放至 32×32，进行 DCT 变换； 取 DCT 结果中第 1～8 行和第 1～8 列（注意 C++ 下标从 0 开始，这里是从第 2 行&#x2F;列开始），即去除了直流分量（DC）及水平、垂直低频分量； 将 8×8 区域按行优先（row-major）展开为 64 个系数； 计算这 64 个系数的中位数； 依次与中位数比较，大于中位数为 1，小于等于为 0，得到 64 位哈希值。 几点补充说明： 第 2 步的均值滤波是为了在缩放前去除高频分量，避免 LANCZOS 等缩放算法对高频过于敏感，这是常见的图像预处理方法； 第 4 步从第 1～8 行&#x2F;列取值，忽略了直流分量和部分低频分量，这样做的合理性值得商榷； 使用中位数作为阈值，可以保证哈希值的熵最大（理论上 0 和 1 各占一半）； 展开顺序为按行优先（row-major）。 3. 主流实现的不足与改进思路在查阅和分析主流实现的基础上，我有如下思考和优化建议： 图像预处理：在缩放前先对图像进行一次 3×3 的高斯滤波（或均值滤波），是因为如 Image.Resampling.LANCZOS 这类缩放算法对高频分量较为敏感。滤波有助于去除高频噪声，使缩放后的图像特征更稳定，这是常见的图像处理手段。 DCT 系数选取：有的实现（如 pHash C++ 版）取 DCT 结果的第 1～8 行&#x2F;列（即从下标 1 开始），这样不仅去除了直流分量（DC），还去除了水平和垂直的低频分量。虽然去除直流分量有助于消除亮度影响，但进一步去除低频分量是否合理值得商榷。通过逆 DCT（IDCT）实验可以发现，只有第一行或第一列有值时，图像结构差异很大，但如果都去除，这些图像的 pHash 结果会完全相同，区分度反而下降。 阈值选取：采用中位数作为阈值，可以保证哈希值的熵最大（理论上 0 和 1 各占一半），提升区分能力。若采用平均值，通常会去掉直流分量后再计算平均值。 系数排列顺序：主流实现多采用按行优先（row-major）展开 8×8 区域。但我认为采用 Zigzag 顺序，即频域能量分布排列会更好（如 JPEG 压缩中的做法）。思路来源：[Not All Bits Are Created Equal](https://nekkidphpprogrammer.blogspot.com&#x2F;2014&#x2F;01&#x2F;not-all-bits-are-created-equal.html) 我的优化思路： DCT 系数区域回归为第 0～7 行&#x2F;列（包含直流分量）； 8×8 DCT 系数采用 Zigzag 顺序排列； 其他细节与主流实现保持一致。 4. Python 优化实现Zigzag 顺序说明Zigzag 顺序常用于 JPEG 压缩，能更好地反映频域能量分布。排列如下： 123456789101112zigzag_8x8 = ( np.asarray([ [0, 1, 5, 6, 14, 15, 27, 28], [2, 4, 7, 13, 16, 26, 29, 42], [3, 8, 12, 17, 25, 30, 41, 43], [9, 11, 18, 24, 31, 40, 44, 53], [10, 19, 23, 32, 39, 45, 52, 54], [20, 22, 33, 38, 46, 51, 55, 60], [21, 34, 37, 47, 50, 56, 59, 61], [35, 36, 48, 49, 57, 58, 62, 63], ]).flatten().argsort()) Python 实现123456789101112from PIL import Image, ImageFilterimport numpy as npimport scipy.fftdef phash_zigzag(image: Image.Image, hash_size=8, img_size=32): # 转为灰度图，滤波后缩放到指定尺寸 image = image.convert(&quot;L&quot;).filter(ImageFilter.BoxBlur(3)).resize((img_size, img_size), Image.Resampling.LANCZOS) # 计算 DCT，取左上角 8×8 区域，按 zigzag 顺序排列 dct_low_freq = scipy.fft.dctn(np.asarray(image), norm=&quot;ortho&quot;, overwrite_x=True)[:hash_size, :hash_size].ravel()[zigzag_8x8] # 以中位数为阈值生成哈希 hash_value = np.packbits(dct_low_freq &gt; np.median(dct_low_freq)).view(np.uint64)[0] return hash_value 5. 总结pHash 算法通过 DCT 提取图像低频特征，主流实现存在一些细节差异。通过分析主流实现的不足，我采用了包含直流分量、zigzag 顺序排列等优化方式,希望本文对理解和改进感知哈希算法有所帮助。 修改历史 时间 修改内容 2025-06-30 增加pHash 算法探究","categories":[],"tags":[]},{"title":"shelvez: a compressed, faster alternative to shelve with JSON and Pydantic support","slug":"shelvez-a-compressed-faster-alternative-to-shelve-with-JSON-and-Pydantic-support","date":"2025-05-19T07:49:24.000Z","updated":"2025-05-19T07:53:21.000Z","comments":true,"path":"posts/62db67aa.html","permalink":"https://blog.ftomin.com/posts/62db67aa.html","excerpt":"What My Project DoesI made a small library called shelvez. It works similarly to Python’s built-in shelve, but adds compression and flexible serialization options. shelvez is a lightweight key-value store with: Zstandard compression for smaller database files Built-in support for Pickle, JSON, and Pydantic model serialization A plug-in serializer interface if you want to define your own Future plans for SQLite-backed transactions The goal is to provide a more flexible and efficient alternative to shelve, while keeping the same simple API.","text":"What My Project DoesI made a small library called shelvez. It works similarly to Python’s built-in shelve, but adds compression and flexible serialization options. shelvez is a lightweight key-value store with: Zstandard compression for smaller database files Built-in support for Pickle, JSON, and Pydantic model serialization A plug-in serializer interface if you want to define your own Future plans for SQLite-backed transactions The goal is to provide a more flexible and efficient alternative to shelve, while keeping the same simple API. Target AudienceThis project may be useful for: Developers who like the convenience of shelve but want smaller and faster storage People building scripts, data pipelines, CLI tools, or experiments Anyone who wants to store structured data (like dicts or models) with minimal setup It’s still early stage, so best suited for prototypes, research, or personal tools rather than production. ComparisonCompared to Python’s built-in shelve, shelvez: Measured using pytest-benchmark with some number simple db[&quot;random_key&quot;] = random_value writes: Backend Mean Write Time File Size shelve ~450 ms 380 KB shelvez ~240–260 ms 308–312 KB Roughly 2× faster and ~20% smaller on disk based on benchmarks using random string data. In real-world usage with more structured or repetitive data, compression is likely to be even more effective. Example Usage12345import shelvez as shelve db = shelve.open(&quot;data.db&quot;)db[&quot;key&quot;] = &quot;value&quot;db.close() 修改历史 时间 修改内容 2025-05-19 fix post 2025-05-19 add post","categories":[],"tags":[]},{"title":"Android系统adb设置proxy","slug":"Android系统adb设置proxy","date":"2024-01-19T12:25:44.000Z","updated":"2024-01-19T12:32:11.000Z","comments":true,"path":"posts/b30c046b.html","permalink":"https://blog.ftomin.com/posts/b30c046b.html","excerpt":"前言最近有需求要对 android 进行代理，下面是使用后的一些总结。 对 android 使用 adb 命令设置代理,先使用adb shell命令进入 adb shell 然后键入 adb 命令如下 1settings put global http_proxy $&#123;proxy_ip&#125;:$&#123;proxy_port&#125; 其中${proxy_ip}和${proxy_port}分别是你要代理的 ip 和端口号。 这条命令使用后，代理是即时生效的。 同时如果你输入下面的命令 1settings list global | grep proxy 会发现 global_http_proxy_host 和 global_http_proxy_port也被自动配上了。","text":"前言最近有需求要对 android 进行代理，下面是使用后的一些总结。 对 android 使用 adb 命令设置代理,先使用adb shell命令进入 adb shell 然后键入 adb 命令如下 1settings put global http_proxy $&#123;proxy_ip&#125;:$&#123;proxy_port&#125; 其中${proxy_ip}和${proxy_port}分别是你要代理的 ip 和端口号。 这条命令使用后，代理是即时生效的。 同时如果你输入下面的命令 1settings list global | grep proxy 会发现 global_http_proxy_host 和 global_http_proxy_port也被自动配上了。 取消代理如果你需要取消代理，使用如下命令 1settings put global http_proxy :0 会立即生效 反之，如果你使用 1settings put global http_proxy ‘’ 是不会立即生效的，需要重启手机，才能取消代理。 设置代理账号和密码如果你的代理需要配置账号和密码 你可以会照着网上的一些命令 像下面这样配置 12345settings put global http_proxy $&#123;proxy_ip&#125;:$&#123;proxy_port&#125;settings put global global_http_proxy_host $&#123;proxy_ip&#125;settings put global global_http_proxy_port $&#123;proxy_port&#125;settings put global global_http_proxy_username $&#123;proxy_username&#125;settings put global global_http_proxy_password $&#123;proxy_password&#125; 其中${proxy_username}和${proxy_passwod}分别是代理的账号和密码 配完之后你会发现没有生效 重启之后也没有生效，并且重启后如果你输入settings list global | grep proxy查询代理配置 会发现global_http_proxy_username和global_http_proxy_password这两项都变成空了 这是因为设备启动时会先查询http_proxy的配置，如果存在值，就将值赋值给global_http_proxy_各项，所以，想要账密生效，就不要配置http_proxy 配置命令如下 12345settings put global http_proxy &#x27;&#x27;settings put global global_http_proxy_host $&#123;proxy_ip&#125;settings put global global_http_proxy_port $&#123;proxy_port&#125;settings put global global_http_proxy_username $&#123;proxy_username&#125;settings put global global_http_proxy_password $&#123;proxy_password&#125; 配置完成后，不会立即生效，需要重启手机。 设置排除列表如果你是使用global_http_proxy_各项设置的代理，并且没有配置http_proxy 那么还可以实现指定域名列表不做代理的功能，实现方式就是在上文命令的基础上加上 1settings put global global_http_proxy_exclusion_list $&#123;url1&#125;,$&#123;url2&#125; 这里的${url1}和${url2}是你不想代理的域名，如果有更多可以继续往后添加 注意域名逗号中间不要有空格 设置 pac 智能代理哈哈，没想到吧，系统代理也支持 pac 功能，使用命令如下 1settings put global globa_proxy_pac_url $&#123;pac_url&#125; 这里的${pac_url}是 pac 文件放置的域名，写法比较复杂，我用的也少，就不细说了。 修改历史 时间 修改内容 2024-01-19 add Android系统adb设置proxy","categories":[],"tags":[{"name":"Android","slug":"Android","permalink":"https://blog.ftomin.com/tags/Android/"},{"name":"Proxy","slug":"Proxy","permalink":"https://blog.ftomin.com/tags/Proxy/"},{"name":"adb","slug":"adb","permalink":"https://blog.ftomin.com/tags/adb/"}]},{"title":"windows wsl2配置ssh server并可以从其他计算机链接","slug":"windows-wsl2配置ssh-server从其他计算机链接","date":"2023-06-01T13:56:03.000Z","updated":"2023-06-01T13:59:33.000Z","comments":true,"path":"posts/dbc07926.html","permalink":"https://blog.ftomin.com/posts/dbc07926.html","excerpt":"前言wsl2是个好东西,但因为网络的问题,wsl2的ip和局域网ip并不在一个层级,如果从其他机器B访问这台机器A的wsl2是不通的.而且还有个问题就是,wsl2的ip是随机分配的,会不停的变动,在本级可以通过localhost来访问,但是其他机器就不能使用了.我查找的教程都是通过比如说端口转发什么,这个如果wsl2的ip变动了,就要重新配置,比较麻烦.我想到一个新的方法就是通过跳板机的方式,先ssh进本机,然后再从本机ssh到wsl2这样的好处就是也不用查询wsl2的ip是多少了,比如你的本机ip是192.168.31.155 用户是 user ,配置好后只需输入ssh root@localhost -J user@192.168.31.155 即可从ssh 进wsl2.接下来讲下配置方式.","text":"前言wsl2是个好东西,但因为网络的问题,wsl2的ip和局域网ip并不在一个层级,如果从其他机器B访问这台机器A的wsl2是不通的.而且还有个问题就是,wsl2的ip是随机分配的,会不停的变动,在本级可以通过localhost来访问,但是其他机器就不能使用了.我查找的教程都是通过比如说端口转发什么,这个如果wsl2的ip变动了,就要重新配置,比较麻烦.我想到一个新的方法就是通过跳板机的方式,先ssh进本机,然后再从本机ssh到wsl2这样的好处就是也不用查询wsl2的ip是多少了,比如你的本机ip是192.168.31.155 用户是 user ,配置好后只需输入ssh root@localhost -J user@192.168.31.155 即可从ssh 进wsl2.接下来讲下配置方式. 配置机器A的ssh安装opensshwin10 win11 都支持安装openssh server,可以参考这个链接:https://learn.microsoft.com/zh-cn/windows-server/administration/openssh/openssh_install_firstuse 若要安装 OpenSSH 组件： 打开“设置”，选择“应用”&gt;“应用和功能”，然后选择“可选功能” 。 扫描列表，查看是否已安装 OpenSSH。 如果未安装，请在页面顶部选择“添加功能”，然后： 查找“OpenSSH 客户端”，再单击“安装” 查找“OpenSSH 服务器”，再单击“安装”设置完成后，回到“应用”&gt;“应用和功能”和“可选功能”，你应会看到已列出 OpenSSH 。 配置openssh这样安装完openssh是不用再设置防火墙的,如果你打开防火墙会发现, windows已经自动配置好了openssh的22端口监听.不过,sshd服务是默认关闭的,需要 打开 服务 -&gt; openssh 右键 启动. 可以在属性里将这个服务设置为自动启动.然后我们就可以尝试从其他机器ssh这台windows了. 查看机器B公钥我们将另外一台机器B的公钥添加到机器A上,这样ssh登陆就不用输入密码了.我的机器B是一台mac,在命令行输入cat ~/.ssh/id_rsa.pub输出的就是机器B的公钥,复制下来.如果找不到文件的话,代表你还没有ssh key ,键入 ssh-keygen 命令,然后一路回车就可在机器B上创建ssh key,然后重新cat ~/.ssh/id_rsa.pub查看公钥. 添加机器B的公钥到机器A在linux下,公钥直接添加到~/.ssh/authorized_keys文件下面就好了.但在windows下面,这里是有一些不一样的,如果你是管理员账户的话(一般家用一个用户都是管理员账户,注意有管理员权限就是管理员账户),那你就要把机器B的公钥添加到C:\\ProgramData\\ssh\\sshd_config\\administrators_authorized_keys文件下面才行.注意: 是ProgramData 不是Program File 禁用密码登陆为了安全起见,我推荐将允许密码登陆给关掉,使用公钥的方式登陆. windows的sshd 的config文件位置是 C:\\ProgramData\\ssh\\sshd_config用记事本或者vscode打开之后找到再最后添加PasswordAuthentication no,即可禁用密码登陆. 重启openssh在开始菜单搜索 服务 ,然后找到 openssh 右键停止 然后再右键运行.即可重启openssh.然后尝试从机器B登陆到机器A试试. 在机器B输入命令ssh user@192.168.31.155注意 user代表你的windows用户名 就是C:\\user文件夹下面的那个你的用户名文件夹的名字. 192.168.31.155就是机器A的ip,可以在powershell输入ipconfig查看. 备注: openssh 调试如果你配置完之后无法正常从机器B ssh到机器A,那么可以手动将 服务 里的 openssh 关掉. 打开powershell,输入sshd -d然后再从机器B ssh 到机器A,powershell会打印出无法连接的原因. 配置机器A的wsl2的ssh重装ssh输入 12sudo apt remove openssh-server -ysudo apt install openssh-server -y 放入公钥如果不存在 ~/.ssh文件夹,那输入 ssh-keygen 生成ssh key然后将机器B的公钥放在~/.ssh/authorized_keys里面注意authorized_keys 文件的权限,最好用chmod 600 ~/.ssh/authorized_keys重设下权限. 重启ssh服务输入下面的命令重启sshd 1systemctl restart ssh 结束这样配置好之后就万事大吉啦,尝试使用ssh登陆吧,输入命令ssh root@localhost -J user@192.168.31.155记得将机器A的ip和用户名替换成自己的. 一些其它方法比如: https://blog.meathill.com/wsl/wsl2-setup-ssh-server-and-connect-from-external-machine.html这样就不用跳板机直接连入wsl2了,但是就没办法进入本机的powershell了. 修改历史 时间 修改内容 2023-06-01 add more tag 2023-06-01 add abbrlink 2023-06-01 add page config windows wsl2 ssh server from other system","categories":[],"tags":[]},{"title":"一个自动投稿视频的思路","slug":"一个自动投稿视频的思路","date":"2022-12-09T09:20:45.000Z","updated":"2023-05-08T15:17:26.000Z","comments":true,"path":"posts/9371e661.html","permalink":"https://blog.ftomin.com/posts/9371e661.html","excerpt":"最近chatgpt很火呀,可以看出已经有基本的分析能力了.那我想就在此基础上录播视频,然后语音转文字后用chatgpt做语义分析,根据chatgpt的建议剪辑出高光时刻.这也算是某种程度上的洗稿吧,因为剪辑的操作是由chatgpt来做的…录播各个直播的视频,然后把高光点自动剪辑出来自动发布.不过感觉根据弹幕数量判断其实也挺好的.就是个思路,执行起来还要看版权问题以及chatgpt的调教,怎么调教成有能力的剪辑man哈哈.电费先按一天5块钱算吧.如果没有版权问题一个月收益分享有150就算不亏运营成本.有时间了来试试看.","text":"最近chatgpt很火呀,可以看出已经有基本的分析能力了.那我想就在此基础上录播视频,然后语音转文字后用chatgpt做语义分析,根据chatgpt的建议剪辑出高光时刻.这也算是某种程度上的洗稿吧,因为剪辑的操作是由chatgpt来做的…录播各个直播的视频,然后把高光点自动剪辑出来自动发布.不过感觉根据弹幕数量判断其实也挺好的.就是个思路,执行起来还要看版权问题以及chatgpt的调教,怎么调教成有能力的剪辑man哈哈.电费先按一天5块钱算吧.如果没有版权问题一个月收益分享有150就算不亏运营成本.有时间了来试试看. 下面是转载的 https://www.bilibili.com/read/cv5276486 2、视频播放计算收益（一般up主，主要收入） 视频播放激励一个视频每有1000播放量就有3元收益。一个优质的视频如果有好几百万的播放量，再加上观众的投币，点赞收藏，可能光一个视频就能获得上万的奖励。 3、观众充电的钱观众充电，也就是送礼物。b站的礼物是小电池。 5、各类创作活动（广大不知名，18线up主） 上首页，或者活动中获得头筹这类，奖金还算可以 这种情况下看,普通的剪出来一个片段其实不能算“自制”的.那多段混剪加上添加字幕呢?再加一些chatgpt的解说呢? 修改历史 时间 修改内容 2023-05-08 增加分节 2022-12-09 增加一点点调查 2022-12-09 add tag 2022-12-09 add page","categories":[],"tags":[]},{"title":"从黑群晖到TrueNAS SCALE","slug":"从黑群晖到truenas-scale","date":"2022-06-01T19:09:34.000Z","updated":"2025-03-02T16:04:45.000Z","comments":true,"path":"posts/8a7ae7d7.html","permalink":"https://blog.ftomin.com/posts/8a7ae7d7.html","excerpt":"前言回忆一下也是有几年了,最开始入坑NAS还是因为星际蜗牛,当时蜗牛矿渣大批量上市,一个机箱只要200左右,刚好当时有两块从笔记本还有PC淘汰下来的硬盘(2T),抱着折腾的心态直接入了两台,一台实验测试最佳实践,一台折腾最新特性.玩了有一年后,又奔着all in one的坑,自己配了一个性能强一点的.硬盘没插几块,也没什么存数据的刚需,但是这NAS家里都堆了三台了(苦笑).这三台NAS一开始都是用的黑群晖,黑群晖的一个优点应该是ui界面比较人性直观,适合小白使用;但是,因为是盗版系统,安全更新是一个大问题,大版本更新的每次跟进都要扒层皮.这对我这种喜欢跟进最新特性的人简直是折磨.另外硬件适配也是针对性的,我用的cpu和主板都较新,不知道哪里不兼容,硬盘不能启用休眠,一休眠就挂.虽然早就想迁移,但群晖的文件系统是私有格式,直接转移硬盘到另一个NAS或者别的系统都是没办法识别数据的.所以看里面已经住了那么多漂亮小姐姐的份上,我也就睁一眼闭一眼.但是这两天开始,那台自配的8盘位NAS开始掉盘了,看了上一篇文章的同学应该知道,我在上面搭建了rss服务,这下连新闻都不能看了.当作一个低成本家庭all in one小服务器用的NAS彻底失去了它的价值,狠狠心,里面的小姐姐都不要了!我要换家!!!注： 目前这套配置已经稳定运行两年了。TRUE NAS系统的升级也趋向稳定了，目前还是比较稳定的。–2024.5.17","text":"前言回忆一下也是有几年了,最开始入坑NAS还是因为星际蜗牛,当时蜗牛矿渣大批量上市,一个机箱只要200左右,刚好当时有两块从笔记本还有PC淘汰下来的硬盘(2T),抱着折腾的心态直接入了两台,一台实验测试最佳实践,一台折腾最新特性.玩了有一年后,又奔着all in one的坑,自己配了一个性能强一点的.硬盘没插几块,也没什么存数据的刚需,但是这NAS家里都堆了三台了(苦笑).这三台NAS一开始都是用的黑群晖,黑群晖的一个优点应该是ui界面比较人性直观,适合小白使用;但是,因为是盗版系统,安全更新是一个大问题,大版本更新的每次跟进都要扒层皮.这对我这种喜欢跟进最新特性的人简直是折磨.另外硬件适配也是针对性的,我用的cpu和主板都较新,不知道哪里不兼容,硬盘不能启用休眠,一休眠就挂.虽然早就想迁移,但群晖的文件系统是私有格式,直接转移硬盘到另一个NAS或者别的系统都是没办法识别数据的.所以看里面已经住了那么多漂亮小姐姐的份上,我也就睁一眼闭一眼.但是这两天开始,那台自配的8盘位NAS开始掉盘了,看了上一篇文章的同学应该知道,我在上面搭建了rss服务,这下连新闻都不能看了.当作一个低成本家庭all in one小服务器用的NAS彻底失去了它的价值,狠狠心,里面的小姐姐都不要了!我要换家!!!注： 目前这套配置已经稳定运行两年了。TRUE NAS系统的升级也趋向稳定了，目前还是比较稳定的。–2024.5.17 硬件说明机箱 是 8盘位的万由机箱cpu 是 intel 10600T内存 是 2666MHz DDR4 162+82主板 是 技嘉小雕(B460M AORUS PRO)主板.因为主板上只有 6口SATA,所以又加了一块SATA3.0 4口拓展卡凑出来8口.电源 是 买机箱的时候送的益衡300W模块.整机功耗加硬盘100W左右,应该是妥妥的够了.如果都是长期不用的硬盘,做好系统休眠的话,待机功耗应该还可以降低到40~50w左右. 关于RAIDNAS系统有一个重要的地方就是他的raid功能,但这更多的是一个企业功能,但是我个人的看法,家庭用户是没有必要使用raid的.一是增加存储成本,使用raid必然至少要占用一或多块体积最大的盘,这一块盘拿出来用于存放数据不好吗?二是riad5看似美好,但如果购买的是同一批次的磁盘,在同一时间损坏的概率很高,性价比最高的raid5恢复的计算需要对磁盘进行全盘读取,对家用磁盘来说这时候很有可能另一块也坏了.三是riad本身是为高可用服务的,如果你有24小时上线的业务,磁盘损坏导致的业务损失可能远远超出单块磁盘,这时候通过一些磁盘冗余,减小出问题的概率还是非常有必要的.但对于家庭用户,估计没什么不能断掉的服务在跑吧,可能屋里每过几个月都会不定时停一次电,这种高可用几乎是没啥必要的.四是增加维护复杂性,组raid以后,几块磁盘就绑定了,迁移的时候要一起迁移,有一块坏了,这些磁盘上的所有内容在进行校验恢复前都没办法继续使用.磁盘写入速度非常大比例的受到写入速度最慢的那块磁盘影响,对于使用多种大小和厂家的磁盘的家庭用户来说,组raid不一定会带来多大的写入上升,甚至还可能因为单块磁盘问题导致整个存储池速度严重变慢.组raid会减少数据丢失的概率,但会依照磁盘数量成倍的上升存储池出问题的概率.五是不方便扩展,组建raid通常是推荐一次到位,而且所有磁盘体积最好一致,但是对于可能nas上都是淘汰下来的像我这种半垃圾佬,组raid就会导致很大的空间浪费.六是SMART,现代的磁盘都已经支持SMART检测,快损坏的磁盘大部分都会现在SMART检测上出现预警,这时候做好迁移就好了.只要维护的好,没必要使用RAID来进行事后补偿.七是丢了又怎么样,重要数据做好多处备份后,不能恢复的数据可能还没一块硬盘值钱哈哈哈哈哈,比如一些虚拟机的历史快照之类的,大不了重新下载和配置喽.综合以上看法,我个人更倾向单盘单存储池的玩法.重要数据做好异地部分而不是使用raid. NAS系统选择nas常见的,大家了解最多的就是群晖和威联通了,这两家都是闭源系统.实际上用了这两年下来,他们的软件服务基本上也都没用上,都是我自己写的脚本,刚需其实就是docker,简单说装个ubuntu然后再装个docker就可以满足了.但怎么说,尊重未知,专业的nas系统自然有其优先的地方,有时候进去才会发现自己需求更方便和稳定的实现方式,这也是个人不断折腾的原因之一吧.除了功能外,系统也最好是开源的,磁盘最好是开源或者通用的格式,不然基本上就和这系统强绑定了,N年以后如果想要迁移就非常的麻烦,已经吃过一次亏自然不想第二次.在这种情况下,系统就是UNRaid和TrueNAS二选一了.unraid很适合家庭用户一把梭,折腾起来也很方便,raid方式也很有特点,单盘冗余备份,只占用空间最大的一块磁盘,后面可以非常简单的对磁盘池进行加减.拥有很多社区插件以及docker支持,但是论坛用户普遍反映unraid的读写速度是个问题,相比其他系统是要慢很多,没用nvme缓存的时候可能写入速度之后50~60MB&#x2F;s.另外unraid是闭源系统,个人对其功能维护还有理念的持续性保持一定程度的怀疑.另外unraid大家普遍反映稳定性不佳,对被黑群晖的宕机恶心的这么久的我来说,系统的稳定性还是挺重要的.相对比的话TrueNAS是开源系统, 本身是为企业NAS服务的,稳定性较好,但缺点就是不直接支持docker的.不过我去官网的时候发现,它们出了一个truenas scale支持docker,而且去年10月已经release了.这不刚好就是一切成熟,一阵愉悦之下我决定就使用TrueNAS SCALE 作为之后几年的个人NAS存储系统. TrueNas SCALE安装不同的NAS系统的安装方式都是略有区别,比如群晖是在每个系统盘上都会安装一个系统,而TrueNAS要求配置单块32g 以上磁盘(HDD or SSD)当作系统盘.注意这块盘就只能做系统不能存数据.做盘比较简单,在官网下载好TrueNAS镜像之后,可以使用balenaEtcher刻录到u盘上,然后插入NAS中,选择U盘启动即可进入安装界面.注意就是系统盘不能再存放数据了.以及因为会不断的写入日志到系统盘,所以官方不再推荐使用一般的U盘安装系统,它们本不是用于频繁写入的,这么玩的寿命通常只能撑半年到一年左右.但是sata口我刚好比较缺,本身8盘就已经用了主板上4个口加上一个4口的sata拓展卡.还有2个m.2接口,还等待以后升级配置的时候用970填上.所以,这里选择使用一个64GB的固态u盘作为系统盘,寿命应该用个3~4年不成问题吧.进入安装界面后等进度条走完,系统就安装好了,TrueNAS SCALE 基于debain,熟悉的朋友对TrueNAS SCALE的命令行应该也是很熟悉.所有的磁盘都挂载在/mnt 目录下.另外有一点要注意的是,基本上不通过GUI的操作都会在系统重启后被还原.这和TrueNAS的定位有关,基本上它把自己当作一个纯粹的企业NAS存储方案提供商,所以不希望用户做太多的自定义操作引入奇奇怪怪的问题.这里拿苹果当例子应该就很好理解了.刚刚的系统盘不能安装数据也是这种理念的体现,要么尊重最佳实践,要么去使用别的系统折腾吧. zfs 介绍zfs基本上被大家叫做第三代文件系统,简单来说,第一代就是读写,第二代就是加入了日志,减少突然宕机时对系统的危害,第三代代表就是zfs了,加入了写时复制(COW),定时快照,raid,自动纠错,自动去重,自动压缩,自动加密等特性. 但是读写速度的话,相比第二代如ext4并没有什么提升,不如说如果关闭zfs的arc缓存后,写入速度就只有ext4的一半. 功能配置sdd auto trim注意trim仅仅针对ssd scrub 配置定时快照设置docker-compose 安装安装好之后就是把之前黑群晖上的服务再重新在TrueNAS上搭建起来.索性个人使用的服务基本上都是通过docker-compose来启动管理的.那接下只要先装好docker-compose就好了.但装好才发现TrueNAS内置了docker,但是却不直接支持docker compsoe,因为TrueNAS使用k3s进行容器编排,作为同样的容器编排工具,docker compose自然与之冲突.去论坛上可以看到与此相关的好多争论,更专业的运维人员希望使用k8s完成更完整的编排,而普通用户又希望使用docker-compose进行简单的部署,但不管如何,k3s不是一个大多数人能接受的方案.在较早的帖子里,大家通常是通过先新建一个虚拟机,然后再在虚拟机里安装docker的方式来解决,不过我们选择TrueNAS SCALE本来就是因为其内置的docker,再新建虚拟机真是非常的不优雅.好在社区倒是提出了一个更好的方式–通过docker in docker技术,使得我们可以建立一个docker-compose容器,然后在该容器内使用docker-compsoe去运行其他容器,这样就能和k3s的编排隔离开来.而且使用中也暂时没发现什么坑.可以说非常完美了.首先添加社区源,这里po一下社区源的文档,上面有很多第三方包,不过我们在意的其实只有docker-compose.一键安装好后,进入命令行运行docker compose命令即可发现现在docker-compose已经成功安装在容器内了,然后就按平常的方式启动docker-compose即可. SMB共享共享额度限制ACL权限同一个文件夹如果想要共享给多个用户的话就要设置ACL权限了. MAC TimeMachine设置配置mac timemachine的方式比较复杂一些,首先 UPS配置家里面的频繁断电还是很伤硬盘的，所以使用一段时间后，还是加上了UPS配置。UPS主要有两个作用一是在短时间断电或者电压波动的时候保持电量平稳，比如半个小时内的多次开断电，那不仅对硬盘的损伤很可观的，而且每次启动系统都要重启启动nas上面跑的各种服务，还是挺麻烦的。二是在长时间断电，UPS电池供电不足的时候，通知NAS主动关机来保护硬盘。 UPS选型目前NAS的功率在100w左右。因为家里面的断电来电的速度还挺快，根据我这两年的经验，大部分断电，比如忘交电费，电表跳闸等，一个小时内都可以恢复，如果超过一个小时不好的，那就可能往往要等好几个小时，所以希望UPS的电池能至少持续供电一个小时吧。论坛上很多人推荐山特的TG-BOX850,电池容量是12V/7AH，在断电的情况下100w输出可以坚持24分钟，价格接近500，优点是群晖官方支持，如果是群晖系统插上去就可以识别UPS电量，并在低电量的时候自动关机。但可惜，我是TRUENAS，作为对比 山克的SK2000的电池容量是12V/9AH*2在100w输出的情况下,如果效率和TG-BOX850一致，那么可以坚持12V*9AH*2/100W*60m*(24m/(12V*7AH/100W*60m))=61.7分钟，和850的价格差不多，但是持续时间是850的2倍还多一点，但缺点就是说明页上没有说明如何低电量的时候主动通知nas关机，所以这个功能的实现，大概率要自己折腾。但大不了到时候使用ping某个不在ups供电的设备是否在线这个方式来判断是不是断电了，如果持续断电一个半小时，那么就主动给nas关机。这个方案的问题在于需要保证ping的设备的稳定，不要在没断电的时候设备离线了，这样nas就自动误关机了。以及工作的负载可能临时高于100w，加上几年后电源蓄电量可能不足标称值，导致提前断电。但不管怎么算，持续的时间都要长于24分钟哈哈哈。所以权衡之下，还是购买了SK2000。另外可以检查nas电源的hold up time，一般来说，切换时间在10ms以内都是可以承受不会关机的范围。 UPS配置买回来后，惊喜的发现SK2000后面有一个usb接口，于是询问客服后得知，其实可以通过一个叫ViewPower的软件链接电脑，然后就可以在电脑上查看UPS的状态。既然有通讯接口，那看起来有机会链接到NAS上，阅读Truenas Scale文档的ups部分之后，发现官方提供了一个支持的品牌列表，在上面搜索了一番后，我发现在nutdrv_qx驱动的文档上写着这么一段话： The nutdrv_qx driver is known to work with various UPSes from Armac, Blazer, Energy Sistem, Fenton Technologies, General Electric, Hunnox, Masterguard, Mustek, Powercool, Voltronic Power, SKE (rebranded by many, many - have I said many? - others… Long story short: if your UPS came with a software called Viewpower, chances are high that it works with this driver with one of the voltronic* protocols or with the mecer one), and many others.可以看到上面说支持Viewpower的UPS通常这个驱动也工作，看来不需要我们在做什么破解工作了。那直接在Truenas Scale 的 系统设置-&gt;服务-&gt;ups 里进行配置就可以了。配置如下：里面的驱动是随便找了一个使用nutdrv_qx驱动的品牌，应该都可以支持。配置好之后，启动ups服务，然后在shell中输入upsc ups命令就可以查看到ups的状态信息，以及驱动信息如下： 12345678910111213141516171819202122232425➜ ~ upsc upsInit SSL without certificate databasebattery.voltage: 27.18device.type: upsdriver.name: nutdrv_qxdriver.parameter.pollfreq: 30driver.parameter.pollinterval: 2driver.parameter.port: autodriver.parameter.synchronous: autodriver.version: 2.8.0driver.version.data: Voltronic-QS-Hex 0.10driver.version.internal: 0.32driver.version.usb: libusb-1.0.26 (API: 0x1000109)input.voltage: 226.6output.frequency: 50.9output.voltage: 226.6ups.beeper.status: enabledups.delay.shutdown: 30ups.delay.start: 180ups.firmware.aux: PM-Pups.load: 7ups.productid: 5161ups.status: OLups.type: offline / line interactiveups.vendorid: 0665 其中，ups.status指示当前的UPS状态，OL代表在线（online）不过信息中只有电压，没有显示电压百分比，查询文档可以知道，因为不同电池规格不一样，所以我们还需要手动设定ups电池的最大电压（充电到100%时候的电压）和最小电压（降电到0%时候的电压）。山克的服务态度非常的好，直接询问客服，他就将技术人员的电话直接给我了。通过询问技术人员，得知最高电压27v，最低一般不会低于22v。所以我们在附加选项（ups.conf）里填入如下参数: 12default.battery.voltage.high=27default.battery.voltage.low=22 再次在shell中输入upsc ups： 12345678910111213141516171819202122232425262728➜ ~ upsc upsInit SSL without certificate databasebattery.charge: 100battery.voltage: 27.18battery.voltage.high: 27battery.voltage.low: 22device.type: upsdriver.name: nutdrv_qxdriver.parameter.pollfreq: 30driver.parameter.pollinterval: 2driver.parameter.port: autodriver.parameter.synchronous: autodriver.version: 2.8.0driver.version.data: Voltronic-QS-Hex 0.10driver.version.internal: 0.32driver.version.usb: libusb-1.0.26 (API: 0x1000109)input.voltage: 226.6output.frequency: 50.9output.voltage: 226.6ups.beeper.status: enabledups.delay.shutdown: 30ups.delay.start: 180ups.firmware.aux: PM-Pups.load: 7ups.productid: 5161ups.status: OLups.type: offline / line interactiveups.vendorid: 0665 可以看到battery.charge: 100出现了，代表了目前的电量是100%。 UPS测试断电，nas正常工作，没有重启，ups电源风扇开始狂转，蜂鸣器发出的响声和风扇几乎持平哈哈。进入shell输入upsc ups检查ups状态，可以看到ups.status: OB,说明进入电源供电状态。放电一个小时后，显示battery.charge: 12,battery.voltage: 22.59，但我们知道带载情况下，显示的电压其实是偏低的，所以实际电量应该还要比显示的多一些。不过能坚持一个小时已经满足要求了。恢复供电，重新检查ups供电，显示ups.status: OL恢复到正常状态。顺便说下LB代表电量过低。这个时候就会通知nas关机。（但是并没有测试） NAS优化NVME磁盘的用途众所周知啊,企业盘虽然容量很大,但是读写很吵,而且家用小服务器会常驻一些服务,比如 bt下载 homeassistant rss等等,这些服务会频繁的小幅度读写磁盘,如果数据库放在hdd企业盘里,那炒豆子的声音就断不了,而且nvme磁盘的小文件随机读写速度要比hdd磁盘高几个量级,从此考虑,常用的热数据,服务等等都放在nvme盘里,hdd盘放一些不经常读取又占空间的大文件,比如电影啊等等. 硬盘休眠和电源设置的说明启动时nas的待机功率在70w,还是比较高的,拔掉8块hdd硬盘后的功率是25w,所以磁盘大概耗掉了45w,还是很高的.那家用存储其实硬盘休眠就非常必要了.一块企业盘的耗电大概是5~8w,按5w算8块就是40w,一个月就是402430&#x2F;1000&#x3D;28.8度.商用电的价格是1度&#x2F;元,大概一年就是350块钱…浪费的电力也是很可观了,这多余的电费钱都能买个百度云盘的年费了.企业盘一般都是不推荐待机的,因为频繁启停会比较伤硬盘,另外企业盘本身也是为24小时运转制作的,所以一直运转的状态下反而要比待机的状态寿命要更有保证.如果某块磁盘没有热数据要存，比如不挂pt什么的,那就可以设置上硬盘休眠。首先进到shell界面, ‘disk stat’命令可以获取硬盘信息.命名的话hdd磁盘一般是从 sda开头,sdb,sdc这样。 arczfs对arc的需求很大,在普通的linux系统上,zfs_arc_max为0,代表最大arc占用是总内存的一半,比如48G的内存就会占用24G用作arc,剩下24G用作系统和应用服务.不过如果你没有那么多docker要跑的话,鉴于arc对zfs系统的巨大作用,我建议将zfs_arc_max设置为总内存的75%.比如总内存48G,zfs_arc_max就设为35G,也就是37580963840设置方法就是在system setting -&gt; Advanced -&gt; Init&#x2F;Shutdown Scripts -&gt; addtype是 “command” ,command 是 “echo 37580963840 &gt;&gt; &#x2F;sys&#x2F;module&#x2F;zfs&#x2F;parameters&#x2F;zfs_arc_max” ,when 是 “pre init” l2arczfs还有一个l2arc,用途就是将一个ssd用于接受arc溢出的数据,这部分数据当再次使用时就直接从ssd中读取到arc.实际使用中l2arc的效果非常不明显,这是因为arc通常的命中率就可以达到99%,l2arc的命中率只有个位数,这代表只有arc未命中的部分也就是那百分之一中只有百分之几的数据可以再从l2arc的数据中命中,这效果非常的差.所以通常的建议是增加arc,也就是总内存的大小到极限,当实在无法增加内存大小,而arc的命中率又比较低(80%)的时候再考虑增加l2arc,不然甚至可能会带来拖慢速度的副作用. 问题分层存储其实我想要一种分层缓存机制,就是常用的数据在ssd盘里,不常用的会逐渐落到hdd盘上(定时以及定条件触发),这样一是读写速度会大幅加快,而是企业盘的炒豆子声音也会减少,因为主要读写都是ssd,hdd盘就是偶尔会连读一下而已.目前还没找到好的家用级别的实现方式. 磁盘每5分钟读取一次使用netdata查看历史数据的时候发现磁盘被每五分钟读取一次,不管有没有新建存储池都一样,如图:这问题很奇怪,SMART的检测时间是30minutes,所以应该不是SMART检测的问题.不过这个倒没有导致硬盘被频繁唤醒,所以就不管了. 安装NVME之后开始每几小时宕机一次在安装了一块从京东购买的970 evo plus 1T后.突然出现系统开始每几小时宕机一次,在系统里也查不到问题日志.鉴于我把系统数据收集池也移到了该块磁盘上,所以判断问题应该是这块磁盘上.所以,拆机检查发现,这个nvme的长度是插在了11cm的m.2槽上,但是没有用m2螺丝固定,应该是因为此导致了打滑或者信号传输error.重新插拔之后,正在观察问题,如果问题依旧复现,更换系统数据收集池到其他磁盘上,看是否能收到错误日志.以及从淘宝下单了一个m2固定螺丝,等待送达之后安装上再看看.–后记,果然是固定的问题,装上螺丝后就再也没重启过了,已经稳定运行几个月了. 后记也是所谓的折腾,真要说的话,家用没有那么大的带宽,机器运行的费用其实也打不平云服务器,比如这台每月电费是30块,8块磁盘大概有1.5w了,主机cpu主板机箱内存应该是6000左右,有2w我可以在阿里云上买一台超高性能的云计算机器了,稳定和可靠程度要吊打家用服务器. 不过,也就是cpu性能了,去查了下10t存储的阿里云三年要7w,还是高性能实例,还没有算上带宽费用,家庭用云服务器还不是那么可靠hhh…不过希望随着带宽的发展,以后都像企业那样,个人只用瘦终端,然后计算上云,用多少花多少钱,这样就能省很多钱,而且减少很多浪费,而且也可以随时更换硬件升级.不致于像现在这样这么折腾. 修改历史 时间 修改内容 2025-03-03 增加ups设置 2023-02-15 增加arc l2arc 的建议 2022-12-09 fix 2022-10-07 删除创建时间 2022-10-07 修改正确的创建时间 2022-10-07 change text 2022-06-05 add sometings 2022-06-04 acl权限 2022-06-02 fix npm page 2022-06-02 add abbrlink 2022-06-02 fix date 2022-06-02 fix 2022-06-02 publish","categories":[],"tags":[{"name":"群晖","slug":"群晖","permalink":"https://blog.ftomin.com/tags/%E7%BE%A4%E6%99%96/"},{"name":"TrueNAS SCALE","slug":"TrueNAS-SCALE","permalink":"https://blog.ftomin.com/tags/TrueNAS-SCALE/"}]},{"title":"在群晖中使用docker搭建TTRSS+RSSHub并启用https","slug":"TTRSS搭建","date":"2022-05-13T01:45:54.000Z","updated":"2022-10-07T07:44:52.000Z","comments":true,"path":"posts/37149971.html","permalink":"https://blog.ftomin.com/posts/37149971.html","excerpt":"前言目前个人获取信息的方式十分的平台化,而每个平台基本上又都是以使用时间为条件给你推荐各种东西,比如奶子啊奶子啊还有奶子啊什么的,搞得我身体很不好.开玩笑,rss可以让我们主动从各个平台获取信息而不被绑架自己的视野,这非常有用.比如b站不会给你推荐抖音上的东西,抖音也不会给你推荐其他平台上的东西,其他平台还有v2ex,知乎,微博,大家因为常用平台不一样看到的东西也非常的不一样.但是跨平台的浏览不得不说又十分的麻烦.还有就是不同平台的排行榜都是处于自己利益定制的,另外还有一些不能在国内轻易访问的网站(非情色).还有就是像孤岛一样的半年不更新一次的个人博客,这种就更难主动去访问了,如果想抓取不同平台的热门内容还有你想关注的内容汇总到一起,RSS就是一个非常棒的一站式工具.当然,只是收集强时间相关的信息上来说.不过很尴尬的是,目前并没有一个可以说特别好用的RSS平台,TTRSS相对来说是比较不错的一个,但用了一阵以后发现启动速度相对来说还是比较慢.嘛,怎么说,只能交给时间解决了.","text":"前言目前个人获取信息的方式十分的平台化,而每个平台基本上又都是以使用时间为条件给你推荐各种东西,比如奶子啊奶子啊还有奶子啊什么的,搞得我身体很不好.开玩笑,rss可以让我们主动从各个平台获取信息而不被绑架自己的视野,这非常有用.比如b站不会给你推荐抖音上的东西,抖音也不会给你推荐其他平台上的东西,其他平台还有v2ex,知乎,微博,大家因为常用平台不一样看到的东西也非常的不一样.但是跨平台的浏览不得不说又十分的麻烦.还有就是不同平台的排行榜都是处于自己利益定制的,另外还有一些不能在国内轻易访问的网站(非情色).还有就是像孤岛一样的半年不更新一次的个人博客,这种就更难主动去访问了,如果想抓取不同平台的热门内容还有你想关注的内容汇总到一起,RSS就是一个非常棒的一站式工具.当然,只是收集强时间相关的信息上来说.不过很尴尬的是,目前并没有一个可以说特别好用的RSS平台,TTRSS相对来说是比较不错的一个,但用了一阵以后发现启动速度相对来说还是比较慢.嘛,怎么说,只能交给时间解决了. 前置知识前置需要了解一些关于docker以及docker-compose的基本知识和基本命令.docker在群晖的安装很简单,只要在套件库里面搜索docker然后安装上就可以了.其它系统的安装见官方页:https://docs.docker.com/get-docker/我是在自己的黑群晖小机器里搭建的.docker版本是20.10.3,docker-compose 版本是1.28.5,注意docker-compose版本最好大于1.17,不然会有点bug. 搭建ttrsss新建一个名叫ttrss的文件夹,然后在里面新建一个名叫docker-compose.yml的文件. 123mkdir ttrsscd ttrsstouch docker-compose.yml 然后在该文件中写入如下内容: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768services: service.rss: image: wangqiru/ttrss:latest container_name: ttrss labels: com.centurylinklabs.watchtower.enable: true environment: SELF_URL_PATH: http://机器ip:31480 # please change to your own domain DB_PASS: ttrss # use the same password defined in `database.postgres` PUID: 1026 PGID: 100 ports: - 31480:80 volumes: - feed-icons:/var/www/feed-icons/ networks: - public_access - service_only - database_only stdin_open: true tty: true depends_on: - service.mercury - service.opencc - database.postgres restart: always service.mercury: # set Mercury Parser API endpoint to `service.mercury:3000` on TTRSS plugin setting page image: wangqiru/mercury-parser-api:latest labels: com.centurylinklabs.watchtower.enable: true networks: - public_access - service_only restart: always service.opencc: # set OpenCC API endpoint to `service.opencc:3000` on TTRSS plugin setting page image: wangqiru/opencc-api-server:latest labels: com.centurylinklabs.watchtower.enable: true environment: NODE_ENV: production networks: - service_only restart: always database.postgres: image: postgres:13-alpine labels: com.centurylinklabs.watchtower.enable: true environment: - POSTGRES_PASSWORD=ttrss # feel free to change the password volumes: - postgres-data:/var/lib/postgresql/data # persist postgres data to ~/postgres/data/ on the host networks: - database_only restart: alwaysvolumes: feed-icons: postgres-data:networks: public_access: # Provide the access for ttrss UI service_only: # Provide the communication network between services only internal: true database_only: # Provide the communication between ttrss and database only internal: true 注意,SELF_URL_PATH 处要填写你启动docker机器的ip,PUID和PGID是docker容器的用户id和组id,这个如果填错了好像也不会怎么样,只要你是用的创建的虚拟卷.在命令行使用docker-compose up -d启动docker-compose容器.然后在浏览器中访问 http:&#x2F;&#x2F;机器ip:31480 就可以看到你的ttrss网站了. 搭建rsshubrsshub的官方网站是: https://docs.rsshub.app/ , 可以给各种各样的网站生成rss订阅源.帮助我们实现跨平台订阅的想法.你可以直接使用在线的rsshub订阅源来访问一些反爬不是特别严格的网站,但某些反爬严格比如微博某个博主的更新,就最好是自建RSSHub服务了.不过搭建也很简单,我们直接在刚才的docker-compose.yml文件中增加一些关于rsshub的内容即可. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108services: service.rss: image: wangqiru/ttrss:latest container_name: ttrss labels: com.centurylinklabs.watchtower.enable: true environment: SELF_URL_PATH: http://机器ip:31480 # please change to your own domain DB_PASS: ttrss # use the same password defined in `database.postgres` PUID: 1026 PGID: 100 ports: - 31480:80 volumes: - feed-icons:/var/www/feed-icons/ networks: - public_access - service_only - database_only stdin_open: true tty: true depends_on: - rsshub - service.mercury - service.opencc - database.postgres restart: always service.mercury: # set Mercury Parser API endpoint to `service.mercury:3000` on TTRSS plugin setting page image: wangqiru/mercury-parser-api:latest labels: com.centurylinklabs.watchtower.enable: true networks: - public_access - service_only restart: always service.opencc: # set OpenCC API endpoint to `service.opencc:3000` on TTRSS plugin setting page image: wangqiru/opencc-api-server:latest labels: com.centurylinklabs.watchtower.enable: true environment: NODE_ENV: production networks: - service_only restart: always rsshub: image: diygod/rsshub restart: always labels: com.centurylinklabs.watchtower.enable: true environment: PORT: 80 NODE_ENV: production CACHE_TYPE: redis REDIS_URL: &#x27;redis://database.redis:6379/&#x27; PUPPETEER_WS_ENDPOINT: &#x27;ws://service.browserless:3000&#x27; networks: - public_access - database_only depends_on: - database.redis - service.browserless service.browserless: image: browserless/chrome labels: com.centurylinklabs.watchtower.enable: true restart: always ulimits: core: hard: 0 soft: 0 database.redis: image: redis:alpine restart: always labels: com.centurylinklabs.watchtower.enable: true volumes: - redis-data:/data networks: - database_only database.postgres: image: postgres:13-alpine labels: com.centurylinklabs.watchtower.enable: true environment: - POSTGRES_PASSWORD=ttrss # feel free to change the password volumes: - postgres-data:/var/lib/postgresql/data # persist postgres data to ~/postgres/data/ on the host networks: - database_only restart: alwaysvolumes: feed-icons: redis-data: postgres-data:networks: public_access: # Provide the access for ttrss UI service_only: # Provide the communication network between services only internal: true database_only: # Provide the communication between ttrss and database only internal: true 然后运行docker-compose up -d即可.因为都在同一个compose文件,也在同一个public_access网络下,所以ttrss可以使用rsshub做域名直接解析到rsshub的ip.想要在ttrss中订阅rsshub的链接,比如b站番剧就是 http://rsshub/bilibili/bangumi/media/9192更详细的文档可以看https://docs.rsshub.app/ 配置watchtower自动更新如果使用本地的RSSHub服务,有一个小问题是它经常更新…,如果手动来的话会很麻烦,所以我们可以使用watchtower来监控他们进行自动更新.我们再新建一个叫watchtower的文件夹,然后在里面再创建一个docker-compose.yml文件 123mkdir rsshubcd rsshubtouch docker-compose.yml 然后在里面写如下内容: 12345678910111213version: &quot;3.8&quot;services: watchtower: image: containrrr/watchtower:latest container_name: watchtower restart: always environment: TZ: Asia/Shanghai WATCHTOWER_LABEL_ENABLE: &quot;true&quot; WATCHTOWER_CLEANUP: &quot;true&quot; WATCHTOWER_SCHEDULE: &quot;0 30 4 * * *&quot; volumes: - /var/run/docker.sock:/var/run/docker.sock 然后运行docker-compose up -d即可启动一个wathtower容器,它会在每天4.30检测并更新容器.如果不经过一些其他特殊配置,watchtower容器一个宿主机只能运行一个,多个会相互冲突.不过一般来说一个就足够了.如果你还有其他docker container 在运行也希望一并检测的话,给对应的容器增加一个com.centurylinklabs.watchtower.enable: true的label即可. 启用https访问ttrss默认是使用http访问的,而现在的chrome浏览器不建议http访问,所以我们可以申请一个https证书,使用nginx将http转成https再访问ttrss.如果要启用https,首先我们需要一个个人域名,在国内买的话需要备案,如果不想要备案的话也可以在一些国外的比如godaddy上注册一个域名.价格应该不会特别贵.如果实在不想买的话就要考虑一些骚操作,不过我还是建议花钱买省心.有一个个人域名会方便很多. 创建acme.sh容器下面我就假设你已经有个一个域名,接下来就是神奇一个https证书.证书的申请可以使用acme.sh,这个是一个自动申请免费证书的工具,还可以检测快到期自动重新申请.我们再新建一个叫acme.sh的文件夹,然后在里面再创建一个docker-compose.yml文件和一个名叫out的文件夹. 1234mkdir acme.shcd acme.shmkdir outtouch docker-compose.yml 然后在里面写如下内容: 12345678910111213141516version: &quot;3.8&quot;services: acme.sh: image: neilpang/acme.sh:latest container_name: acme.sh restart: always labels: com.centurylinklabs.watchtower.enable: true environment: GD_Secret: MYSELF_PRIVETE_SECRET GD_Key: MYSELF_PRIVETE_KEY volumes: - /var/run/docker.sock:/var/run/docker.sock - ./out:/acme.sh command: daemon 因为我是在godaddy上申请的,所以申请证书就需要填入这里的GD_Secret 和GD_Key两个内容.这两个值可以在godaddy的开发者网站上申请.网址是: https:&#x2F;&#x2F;这里有一个网址等待补全.com&#x2F;使用docker-compose up -d即可启动acme.sh容器,它会在后台检测你已经申请的证书是否到期并续期. 申请https证书然后注册一个账号 1sudo docker exec acme.sh --register-account -m youremail@mail.com 注意youremail@mail.com是填你自己的邮箱地址.然后敲下面的命令开始申请证书,注意yourdomain.com是填你要申请证书的域名,请确保这个域名你自己是拥有者. 1sudo docker exec acme.sh --issue --dns dns_gd -d yourdomain.com 这个命令会申请一个证书,并且把它保存到/acme.sh/out/yourdomain.com目录下.不过我们不会直接操作out目录下的内容.也不会去手动copy它,这样他不会自动更新. 创建nginx容器接下来我们创建一个nginx容器.在ttrss的docker-compose.yml文件中,我们增加一些内容: 1等待补全 导入https证书到ngnix在路由器配置DNS域名劫持在路由器设置域名DNS解析劫持. 暴露TTRSS到公网访问这样我们就可以在本地的局域网愉快的使用ttrss了.不过如果出门怎么办呢,rss非常适合在坐地铁的使用使用不是吗?只能在家用也太不方便了.所以我们要将tttrss暴露到公网,前一步的启用https也是为了增加暴漏到公网的安全性.这一步我们需要有一个固定的公网ip地址,或者DDNS,不过家用ip启动web服务是违法的,如果不备案的话我推荐是购买一个云服务器(国外),以及国外域名,这样会省很多事,不然还是乖乖备案叭. 修改历史 时间 修改内容 2022-10-07 删除创建时间 2022-10-07 修改正确的创建时间 2022-06-02 add abbrlink 2022-05-13 update package 2022-05-13 修改格式 2022-05-13 remove categories 2022-05-13 新文章","categories":[],"tags":[{"name":"TTRSS","slug":"TTRSS","permalink":"https://blog.ftomin.com/tags/TTRSS/"},{"name":"docker","slug":"docker","permalink":"https://blog.ftomin.com/tags/docker/"},{"name":"RSSHub","slug":"RSSHub","permalink":"https://blog.ftomin.com/tags/RSSHub/"},{"name":"Nginx","slug":"Nginx","permalink":"https://blog.ftomin.com/tags/Nginx/"},{"name":"frp","slug":"frp","permalink":"https://blog.ftomin.com/tags/frp/"},{"name":"https","slug":"https","permalink":"https://blog.ftomin.com/tags/https/"},{"name":"群晖","slug":"群晖","permalink":"https://blog.ftomin.com/tags/%E7%BE%A4%E6%99%96/"},{"name":"watchtower","slug":"watchtower","permalink":"https://blog.ftomin.com/tags/watchtower/"}]},{"title":"你好-世界","slug":"你好-世界","date":"2022-05-11T13:57:09.000Z","updated":"2022-10-07T07:17:32.000Z","comments":true,"path":"posts/97d578eb.html","permalink":"https://blog.ftomin.com/posts/97d578eb.html","excerpt":"前言一直以来都想搭建一个博客,但是又觉的维护起来很麻烦.比如需要要服务器,需要个人域名,域名证书,网站备案等等.或者就是放在第三方博客平台上,但是发表的文章导出很麻烦,格式不够自由还要经过各种各样的审查和屏蔽.另外就是一个个人博客通常来说大部分人的都没有什么访问,缺少引流方式和个人独特性的时候,这博客基本上就自己访问简直就是自闭.自己大部分时候又是一个潜水党.种种评估下来,搭建个人博客的事情就一直搁置中.不过,时间是一个很好的东西,几年下来发现个人域名,服务器什么也都有了,在做一些个人小爱好的时候发现网上的资料也不是完全足够,免不了还是要自己踩一些小坑.这里的坑部分是因为自己的水平跟不上文章的作者,部分是因为某些工具或者框架迭代导致的过时.然后突然发现,那我也是可以写一些东西让其他人,或者同水平的朋友少踩坑的,建立博客的意义就有了. 最近在浏览其他网友的博文的时候发现有不少网友使用了hexo的框架,大致检索了下发现十分轻便,博文可以直接markdown语法,非常简单.初期可以直接搭建在github page上,启动成本很低.如果真的不错也,出于网络问题可以再迁移到国内的个人服务器上,又因为是markdown语法,跨框架迁移起来也很方便,再加上最近确实很闲,这让我动了实际搭建一个博客的行动理由.从这里大抵可以看出我是一个想的挺多不怎么愿意动手的人,因为重复折腾真的会让人回忆起来觉的很浪费生命,那这样还不如花费在一些直接收获快乐的垃圾事情上,没错,我说的就是打游戏.","text":"前言一直以来都想搭建一个博客,但是又觉的维护起来很麻烦.比如需要要服务器,需要个人域名,域名证书,网站备案等等.或者就是放在第三方博客平台上,但是发表的文章导出很麻烦,格式不够自由还要经过各种各样的审查和屏蔽.另外就是一个个人博客通常来说大部分人的都没有什么访问,缺少引流方式和个人独特性的时候,这博客基本上就自己访问简直就是自闭.自己大部分时候又是一个潜水党.种种评估下来,搭建个人博客的事情就一直搁置中.不过,时间是一个很好的东西,几年下来发现个人域名,服务器什么也都有了,在做一些个人小爱好的时候发现网上的资料也不是完全足够,免不了还是要自己踩一些小坑.这里的坑部分是因为自己的水平跟不上文章的作者,部分是因为某些工具或者框架迭代导致的过时.然后突然发现,那我也是可以写一些东西让其他人,或者同水平的朋友少踩坑的,建立博客的意义就有了. 最近在浏览其他网友的博文的时候发现有不少网友使用了hexo的框架,大致检索了下发现十分轻便,博文可以直接markdown语法,非常简单.初期可以直接搭建在github page上,启动成本很低.如果真的不错也,出于网络问题可以再迁移到国内的个人服务器上,又因为是markdown语法,跨框架迁移起来也很方便,再加上最近确实很闲,这让我动了实际搭建一个博客的行动理由.从这里大抵可以看出我是一个想的挺多不怎么愿意动手的人,因为重复折腾真的会让人回忆起来觉的很浪费生命,那这样还不如花费在一些直接收获快乐的垃圾事情上,没错,我说的就是打游戏. 搭建搭建很简单,需要一点点前端的知识,不了解的话就大致百度下应该就ok.然后照着命令敲就行了,我参考了https://tding.top/archives/7f189df5.htmlhttps://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html这两位的内容,可以实现一个博客的搭建.hexo new &quot;title-name&quot; 可以创建一个新的博客文章,然后写就完事了.注意hexo s会启动一个服务器方面本地预览,修改内容后直接F5刷新即可,不需要提前运行hexo g编译静态页面,因为会自动编译.自动部署和手动部署都要求先提前设置好_config.yml内的deploy相关配置.比如我要把编译的静态页面内容放到同仓库的gh-pages分支,就按照配置成下面的样子即可. 123456# Deployment## Docs: https://hexo.io/docs/one-command-deploymentdeploy: type: &#x27;git&#x27; repository: https://github.com/touxiaoling/touxiaoling.github.io.git # 用https或者ssh均可 branch: gh-pages 折腾再往后的折腾就是自动编译,域名自定义,theme切换,更换到个人服务器上(不过毕竟本人也不是运维.对于个人服务器的安全和稳定性其实一直都没谱),家里的nas跑了一些服务基本上一个月停电断网什么的都会有一次,感觉也不是多稳定.所以如果没有更简单的方式,也没有特别的需求可能还是会一直在github page上. 显示rss订阅参考: https://juejin.cn/post/7012255009593098254在_config.yml里添加下面的内容即可: 123456789101112plugins: hexo-generate-feed​# rss配置feed: type: atom path: atom.xml limit: 20 hub: content: content_limit: 140 content_limit_delim: &#x27; &#x27; order_by: -date 更换主题主题更换到next,链接是: https://github.com/theme-next/hexo-theme-next推荐使用npm安装,这样后面切换github action 的时候要简单很多. 1$ npm install hexo-theme-next next支持四种样式,我个人比较喜欢Pisces,官方对这个样式的形容是fresh like your neighbor&#39;s daughter,很有趣. 关于主题的 _config.next.yml 文件hexo5以后支持在根目录下创建一个_config.next.yml文件,在这个文件里面直接配置主题的参数而不是在主题包下面的_config.yml下,方便更新,和主题包的更新分离. 自动编译可以采用github actions自动编译,这样就只用push源码到remote仓库就好了.官方教程: https://hexo.io/docs/github-pages这里有一点坑,就是注意里面_config.yml里的 deploy 属性里的 repository 链接要是https的,不然不能使用GITHUB_TOKEN .另外 仓库设置里要给GITHUB_TOKEN 读写仓库的权限,默认是只有读仓库的权限,这样触发action的时候会提示bot push失败. 自定义域名自定义域名我参考了: https://zhuanlan.zhihu.com/p/35708814直接在source文件夹下创建一个CNAME文件即可,文件内容就是你自己的的域名.然后去域名配置的网站新建一个CNAME解析,比如我是将blog子域名解析到touxiaoling.github.io.等待几分钟就可以了. tag 显示参考了: https://linlif.github.io/2017/05/27/Hexo使用攻略-添加分类及标签/没什么太需要注意的,跟着敲就好了. 站点地图参考了: https://eericzeng.github.io/2019/07/14/hexo博客站点sitemap的使用/ 添加评论查询了一些发现还是比较麻烦不怎么优雅,要插入一些第三方的服务才能实现,那这样还是等网站打算折腾个后端以后再去做吧. 图床博文难免会有插入图片的需求最简单的方式就是将图片直接存到代码仓库,但是github的仓库是有体积限制的,小的时候还好,等图片多了就会非常尴尬了.而且每次pull代码的时候都会把图片pull下来,体积会非常的大.那图床自然是一个难免的存在.这里我们使用github的另一个仓库作为图床,然后通过cnd加速访问.这里参考了这位大佬的博文,各位也可以去看下. 后记持续更新中. 修改历史 时间 修改内容 2022-10-07 自动添加创建时间 2022-10-07 修改正确的创建时间 2022-06-02 add abbrlink 2022-06-02 publish 2022-05-13 update package 2022-05-12 优化插件 2022-05-12 美化样式 2022-05-12 增加站点地图 2022-05-12 change scheme to pisces 2022-05-12 补充说明 2022-05-12 fix tag 2022-05-12 fix 2022-05-12 fix 2022-05-12 fix 2022-05-12 fix 2022-05-12 fix 2022-05-12 set git action 2022-05-12 init","categories":[],"tags":[{"name":"next","slug":"next","permalink":"https://blog.ftomin.com/tags/next/"},{"name":"hexo","slug":"hexo","permalink":"https://blog.ftomin.com/tags/hexo/"}]}],"categories":[],"tags":[{"name":"Android","slug":"Android","permalink":"https://blog.ftomin.com/tags/Android/"},{"name":"Proxy","slug":"Proxy","permalink":"https://blog.ftomin.com/tags/Proxy/"},{"name":"adb","slug":"adb","permalink":"https://blog.ftomin.com/tags/adb/"},{"name":"群晖","slug":"群晖","permalink":"https://blog.ftomin.com/tags/%E7%BE%A4%E6%99%96/"},{"name":"TrueNAS SCALE","slug":"TrueNAS-SCALE","permalink":"https://blog.ftomin.com/tags/TrueNAS-SCALE/"},{"name":"TTRSS","slug":"TTRSS","permalink":"https://blog.ftomin.com/tags/TTRSS/"},{"name":"docker","slug":"docker","permalink":"https://blog.ftomin.com/tags/docker/"},{"name":"RSSHub","slug":"RSSHub","permalink":"https://blog.ftomin.com/tags/RSSHub/"},{"name":"Nginx","slug":"Nginx","permalink":"https://blog.ftomin.com/tags/Nginx/"},{"name":"frp","slug":"frp","permalink":"https://blog.ftomin.com/tags/frp/"},{"name":"https","slug":"https","permalink":"https://blog.ftomin.com/tags/https/"},{"name":"watchtower","slug":"watchtower","permalink":"https://blog.ftomin.com/tags/watchtower/"},{"name":"next","slug":"next","permalink":"https://blog.ftomin.com/tags/next/"},{"name":"hexo","slug":"hexo","permalink":"https://blog.ftomin.com/tags/hexo/"}]}